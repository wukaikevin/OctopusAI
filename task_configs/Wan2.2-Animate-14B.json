{
  "app_id": "Wan2.2-Animate-14B",
  "name": "数字人驱动-Wan2.2-Animate-14B",
  "description": "基于Wan2.2-Animate-14B模型的视频人物替换工具，能够将输入视频中的人物动作与提供的人物照片进行结合，生成包含指定人物的新视频。用户可以自定义视频分辨率和提示词，以实现个性化的视频生成效果。算力要求：H100-80G或等效算力以上，支持多卡加速计算。",
  "author": "Kevin Wu",
  "homepage": "https://github.com/wukaikevin",
  "email": "wuk@qq.com",
  "inputs": [
    {
      "label": "提示词",
      "field_name": "prompt",
      "type": "textarea",
      "default_value": "视频中的人物在做动作",
      "editable": true,
      "required": false
    },
    {
      "label": "人物照片",
      "field_name": "image",
      "type": "file",
      "file_extensions": [
        "jpg",
        "png",
        "jpeg"
      ],
      "default_value": "",
      "editable": true,
      "required": true
    },
    {
      "label": "参考视频",
      "field_name": "video",
      "type": "file",
      "file_extensions": [
        "mp4"
      ],
      "default_value": "",
      "editable": true,
      "required": true
    },
    {
      "label": "视频尺寸",
      "field_name": "resolution",
      "type": "select",
      "default_value": "480 832",
      "editable": true,
      "required": true,
      "options": [
        { "label": "竖板-480P (480*832)", "value": "480 832" },
        { "label": "竖板-720P (720*1280)", "value": "720 1280" },
        { "label": "横板-480P (832*480)", "value": "832 480" },
        { "label": "横板-720P (1280*720)", "value": "1280 720" }
      ]
    },
    {
      "label": "驱动模式",
      "field_name": "drive_mode",
      "type": "select",
      "default_value": "replace",
      "editable": true,
      "required": true,
      "options": [
        { "label": "照片人物替换视频人物", "value": "replace" },
        { "label": "照片人物模仿视频动作", "value": "animate" }
      ]
    },
    {
      "label": "音频合成",
      "field_name": "audio",
      "type": "file",
      "file_extensions": [
        "mp4",
        "mp3",
        "wav"
      ],
      "default_value": "",
      "editable": true,
      "required": false
    }
  ],
  "variables": {
    "work_dir": "$HOME/Wan2.2-Animate-14B"
  },
  "server_output_file": "",
  "server_output_dir": "/tmp/Wan2.2-Animate-14B_results",
  "model_path": "$HOME/.cache/Wan2.2-Animate-14B",
  "installs": [
    {
      "env_name": "Wan2.2-Animate-14B",
      "python_version": "3.12",
      "cuda_version": "12.9",
      "commands": [
        "rm -rf {work_dir}",
        "mkdir -p {server_output_dir}",
        "mkdir -p {model_path}",
        "export TORCH_CUDA_ARCH_LIST=\"6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0\" && export FORCE_CUDA=1 && export MAX_JOBS=4",
        "apt-get install sox libsox-dev libgl1 unzip ffmpeg libx264-dev -y",
        "conda install pytorch=2.9.* torchvision sam2 ffmpeg=7.1.1 -c conda-forge -c pytorch -y",
        "pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.1/flash_attn-2.8.1+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_x86_64.whl",
        "git clone https://github.com/Wan-Video/Wan2.2.git {work_dir}",
        "cd {work_dir}",
        "grep -v \"flash_attn\" requirements.txt > requirements_base.txt",
        "pip install -r requirements_base.txt",
        "grep -v \"sam2\" requirements_animate.txt > requirements_animate_no_sam.txt",
        "pip install -r requirements_animate_no_sam.txt",
        "pip install -r requirements_s2v.txt",
        "pip install onnxruntime-gpu",
        "pip install opencv-python moviepy imageio[ffmpeg] imageio-ffmpeg numpy pillow",
        "pip install --upgrade transformers peft diffusers",
        "pip install huggingface_hub[cli]"
      ]
    }
  ],
  "batch": [
    {
      "name": "环境准备",
      "env_name": "Wan2.2-Animate-14B",
      "commands":[
        "hf download Wan-AI/Wan2.2-Animate-14B --local-dir {model_path}"
      ]
    },
    {
      "name": "视频融合",
      "env_name": "Wan2.2-Animate-14B",
      "commands": [
        "rm -rf {server_output_dir}/*",
        "cd {work_dir}",
        "python -c \"import torch; print(f'PyTorch版本: {torch.__version__}'); print(f'CUDA是否可用: {torch.cuda.is_available()}'); (print(f'CUDA版本: {torch.version.cuda}'), print(f'cuDNN版本: {torch.backends.cudnn.version()}'), print(f'GPU数量: {torch.cuda.device_count()}'), [print(f'GPU {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]) if torch.cuda.is_available() else None\"",
        "export gpu_num=$(python -c \"import torch; print(torch.cuda.device_count())\")",
        "if [[ \"{drive_mode}\" == \"replace\" ]]; then",
        "echo \"以替换模式执行\"",
        "python ./wan/modules/animate/preprocess/preprocess_data.py --ckpt_path {model_path}/process_checkpoint --video_path {video} --refer_path {image} --save_path ./process_results --resolution_area {resolution} --iterations 3 --k 7 --w_len 1 --h_len 1 --replace_flag",
        "python -m torch.distributed.run --nnodes 1 --nproc_per_node $gpu_num generate.py --task animate-14B --ckpt_dir {model_path} --src_root_path ./process_results/  --refert_num 1 --replace_flag --use_relighting_lora --prompt \"{prompt}\" $([ \"$gpu_num\" -gt 1 ] && echo \"--dit_fsdp --t5_fsdp\") --ulysses_size $gpu_num --save_file {server_output_dir}/video_only.mp4",
        "else",
        "echo \"以动画模式执行\"",
        "python ./wan/modules/animate/preprocess/preprocess_data.py --ckpt_path {model_path}/process_checkpoint --video_path {video} --refer_path {image} --save_path ./process_results --resolution_area {resolution} --retarget_flag",
        "python -m torch.distributed.run --nnodes 1 --nproc_per_node $gpu_num generate.py --task animate-14B --ckpt_dir {model_path} --src_root_path ./process_results/  --refert_num 1 --prompt \"{prompt}\" $([ \"$gpu_num\" -gt 1 ] && echo \"--dit_fsdp --t5_fsdp\") --ulysses_size $gpu_num --save_file {server_output_dir}/video_only.mp4",
        "fi"
      ]
    },
    {
      "name": "融合音频",
      "env_name": "Wan2.2-Animate-14B",
      "required_inputs": [
        "audio"
      ],
      "commands": [
        "ffmpeg -i {server_output_dir}/video_only.mp4 -i {audio} -c:v copy -map 0:v -map 1:a -shortest -y {server_output_dir}/video_complate.mp4"
      ]
    }
  ],
  "endpoint": "echo \"{server_output_dir}/video_complate.mp4\""
}