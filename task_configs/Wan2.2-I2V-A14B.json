{
  "app_id": "Wan2.2-I2V-A14B",
  "name": "图像生成视频-Wan2.2-I2V-A14B",
  "description":"基于Wan2.2-I2V-A14B模型的图像生成视频工具，支持根据用户输入的提示词和参考图像生成高质量的视频内容。用户可以自定义视频分辨率，以满足不同的创作需求。算力要求：H100-80G或等效算力以上，支持多卡(多卡的话需要是4卡/8卡)加速计算。",
  "author":"Kevin Wu",
  "homepage":"https://github.com/wukaikevin",
  "email":"wuk@qq.com",
  "inputs": [
    {
      "label": "视频创作提示词（每行提示词一个片段，多行多片段，每个片段最多5秒）",
      "field_name": "prompt", 
      "type": "prompt",
      "default_value": "镜头一\n镜头二\n镜头三",
      "editable": true,
      "required": true
    },
    {
      "label": "参考图片(作为首帧图片，后续每个片段的生成都基于上一个片段的最后一帧）",
      "field_name": "image",
      "type": "file",
      "file_extensions": ["png","jpg","jpeg"],
      "default_value": "",
      "editable": true, 
      "required": true
    },
    {
      "label": "视频尺寸",
      "field_name": "resolution",
      "type": "select",
      "default_value": "480*832",
      "editable": true,
      "required": true,
      "options": [
        { "label": "竖板-480P (480*832)", "value": "480*832" },
        { "label": "竖板-720P (720*1280)", "value": "720*1280" },
        { "label": "横板-480P (832*480)", "value": "832*480" },
        { "label": "横板-720P (1280*720)", "value": "1280*720" }
      ]
    },
    {
      "label": "融合音频（如果音频的时长超过视频，那么音频将被截断。反之视频时长超过音频，则视频将被截断。合成的视频时长取两者中最短的一方时间。）",
      "field_name": "audio",
      "type": "file",
      "file_extensions": ["mp4","mp3","wav"],
      "default_value": "",
      "editable": true, 
      "required": false
    }
  ],
  "variables": {
    "work_dir": "$HOME/Wan2.2-I2V-A14B"
  },
  
  "server_output_file": "/tmp/Wan2.2-I2V-A14B_results/result.mp4",
  "server_output_dir":"",
  "model_path": "$HOME/.cache/Wan2.2-I2V-A14B-BF16",
  
  "installs":[
    {
      "env_name":"Wan2.2-I2V-A14B",
      "python_version":"3.12",
      "cuda_version":"12.9",
      "commands":[
        "rm -rf {work_dir}",
        "mkdir -p {model_path}",
        "export TORCH_CUDA_ARCH_LIST=\"6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0\" && export FORCE_CUDA=1 && export MAX_JOBS=4",
        "apt-get install sox libsox-dev libgl1 unzip ffmpeg -y",
        "conda install pytorch=2.9.* torchvision ffmpeg=7.1.1 -c conda-forge -c pytorch -y",
        "pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.1/flash_attn-2.8.1+cu12torch2.9cxx11abiTRUE-cp312-cp312-linux_x86_64.whl",
        "git clone https://github.com/Wan-Video/Wan2.2.git {work_dir}",
        "cd {work_dir}",
        "grep -v \"flash_attn\" requirements.txt > requirements_base.txt",
        "pip install -r requirements_base.txt",
        "pip install -r requirements_s2v.txt",
        "pip install onnxruntime-gpu",
        "pip install moviepy",
        "pip install --upgrade transformers peft diffusers",
        "pip install huggingface_hub[cli] modelscope"
      ]
    }
  ],
  "batch": [
    {
      "name": "环境准备",
      "env_name": "Wan2.2-I2V-A14B",
      "commands":[
        "hf download Wan-AI/Wan2.2-I2V-A14B --local-dir {model_path}",
        "#modelscope download Wan-AI/Wan2.2-I2V-A14B-BF16 --local_dir {model_path}"
      ]
    },
    {
      "name": "视频生成",
      "env_name": "Wan2.2-I2V-A14B",
      "commands": [
        "mkdir -p $(dirname {server_output_file})",
        "cd {work_dir}",
        "cp /tmp/Wan2.2-Expand/generate-i2v.py {work_dir}/generate2.py",
        "python -c \"import torch; print(f'PyTorch版本: {torch.__version__}'); print(f'CUDA是否可用: {torch.cuda.is_available()}'); (print(f'CUDA版本: {torch.version.cuda}'), print(f'cuDNN版本: {torch.backends.cudnn.version()}'), print(f'GPU数量: {torch.cuda.device_count()}'), [print(f'GPU {i}: {torch.cuda.get_device_name(i)}') for i in range(torch.cuda.device_count())]) if torch.cuda.is_available() else None\"",
        "export gpu_num=$(python -c \"import torch; print(torch.cuda.device_count())\")",
        "#export gpu_num=1",
        "export TORCH_NCCL_ENABLE_MONITORING=0",
        "export NCCL_IB_DISABLE=1",
        "python -c \"import torch;torch.cuda.empty_cache()\"",
        "torchrun --nproc_per_node=$gpu_num generate2.py --task i2v-A14B --size {resolution} --ckpt_dir {model_path} $([ \"$gpu_num\" -gt 1 ] && echo \"--dit_fsdp --t5_fsdp\") --ulysses_size $gpu_num --prompt \"{prompt}\" --image {image} --offload_model True --convert_model_dtype --multi_prompt --save_file {server_output_file}"
      ]
    },
    {
      "name": "融合音频",
      "env_name": "Wan2.2-I2V-A14B",
      "required_inputs": ["audio"],
      "commands": [
        "ffmpeg -i {server_output_file} -i {audio} -c:v copy -c:a aac -map 0:v -map 1:a -shortest -y {server_output_file}.meg.mp4",
        "mv {server_output_file}.meg.mp4 {server_output_file}",
        "ffprobe {server_output_file}"
      ]
    }
  ],
  "uploads":[
    {
      "source_path": "Wan2.2-Expand/generate-i2v.py",
      "server_path": "/tmp/Wan2.2-Expand/generate-i2v.py"
    }
  ],
  "endpoint" : "echo \"{server_output_file}\""
}